from typing import List, Optional, Dict, Any
from pydantic import Field, field_validator, ConfigDict
from .base_models import OpenAIBaseModel
from .types import ModelNameType


class ChatCompletionChoice(OpenAIBaseModel):
    index: int = Field(..., description="Index of the choice in the list of choices.")
    message: Dict[str, str] = Field(
        ..., description="The message generated by the model."
    )
    finish_reason: str = Field(
        ..., description="The reason why the model finished generating."
    )

    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": "Hello! How can I assist you today?",
                },
                "finish_reason": "stop",
            }
        }
    )


class ChatCompletionResponse(OpenAIBaseModel):
    id: str = Field(..., description="Unique identifier for the completion.")
    object: str = Field(..., description="Object type, always 'chat.completion'.")
    created: int = Field(
        ..., description="Unix timestamp of when the completion was created."
    )
    model: ModelNameType = Field(..., description="The model used for the completion.")
    choices: List[ChatCompletionChoice] = Field(
        ..., description="List of generated completions."
    )
    usage: Dict[str, int] = Field(
        ..., description="Token usage information for the request."
    )

    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "id": "chatcmpl-123",
                "object": "chat.completion",
                "created": 1677652288,
                "model": "gpt-3.5-turbo",
                "choices": [
                    {
                        "index": 0,
                        "message": {
                            "role": "assistant",
                            "content": "Hello! How can I assist you today?",
                        },
                        "finish_reason": "stop",
                    }
                ],
                "usage": {
                    "prompt_tokens": 9,
                    "completion_tokens": 12,
                    "total_tokens": 21,
                },
            }
        }
    )


class CompletionChoice(OpenAIBaseModel):
    text: str = Field(..., description="The generated text.")
    index: int = Field(..., description="Index of the choice in the list of choices.")
    logprobs: Optional[Dict[str, Any]] = Field(
        None, description="Log probabilities of the tokens in the generated text."
    )
    finish_reason: str = Field(
        ..., description="The reason why the model finished generating."
    )

    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "text": "Hello! How can I assist you today?",
                "index": 0,
                "logprobs": None,
                "finish_reason": "stop",
            }
        }
    )


class CompletionResponse(OpenAIBaseModel):
    id: str = Field(..., description="Unique identifier for the completion.")
    object: str = Field(..., description="Object type, always 'text_completion'.")
    created: int = Field(
        ..., description="Unix timestamp of when the completion was created."
    )
    model: ModelNameType = Field(..., description="The model used for the completion.")
    choices: List[CompletionChoice] = Field(
        ..., description="List of generated completions."
    )
    usage: Dict[str, int] = Field(
        ..., description="Token usage information for the request."
    )

    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "id": "cmpl-123",
                "object": "text_completion",
                "created": 1677652288,
                "model": "gpt-3.5-turbo",
                "choices": [
                    {
                        "text": "Hello! How can I assist you today?",
                        "index": 0,
                        "logprobs": None,
                        "finish_reason": "stop",
                    }
                ],
                "usage": {
                    "prompt_tokens": 9,
                    "completion_tokens": 12,
                    "total_tokens": 21,
                },
            }
        }
    )


class EmbeddingResponse(OpenAIBaseModel):
    object: str = Field(..., description="Object type, always 'list'.")
    data: List[Dict[str, Any]] = Field(..., description="List of embedding objects.")
    model: ModelNameType = Field(..., description="The model used for the embeddings.")
    usage: Dict[str, int] = Field(
        ..., description="Token usage information for the request."
    )

    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "object": "list",
                "data": [
                    {
                        "object": "embedding",
                        "embedding": [0.0023064255, -0.009327292, -0.0028842222],
                        "index": 0,
                    }
                ],
                "model": "gpt-3.5-turbo",
                "usage": {"prompt_tokens": 8, "total_tokens": 8},
            }
        }
    )


class ResponseInfo(OpenAIBaseModel):
    status_code: int = Field(..., description="HTTP status code of the response.")
    request_id: str = Field(..., description="Unique identifier for the request.")
    body: Dict[str, Any] = Field(..., description="Response body.")


class RequestOutputObject(OpenAIBaseModel):
    id: str = Field(..., description="Unique identifier for the request output.")
    custom_id: str = Field(
        ..., description="Custom identifier provided in the request."
    )
    response: Optional[ResponseInfo] = Field(
        None, description="Response information if the request was successful."
    )
    error: Optional[Dict[str, str]] = Field(
        None, description="Error information if the request failed."
    )

    @field_validator("response", "error")
    def validate_response_and_error(cls, v, info):
        if info.data.get("response") is None and info.data.get("error") is None:
            raise ValueError("Either 'response' or 'error' must be provided")
        if info.data.get("response") is not None and info.data.get("error") is not None:
            raise ValueError("Only one of 'response' or 'error' should be provided")
        return v

    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "id": "batch_req_wnaDys",
                "custom_id": "request-2",
                "response": {
                    "status_code": 200,
                    "request_id": "req_c187b3",
                    "body": {
                        "id": "chatcmpl-9758Iw",
                        "object": "chat.completion",
                        "created": 1711475054,
                        "model": "gpt-3.5-turbo",
                        "choices": [
                            {
                                "index": 0,
                                "message": {
                                    "role": "assistant",
                                    "content": "2 + 2 equals 4.",
                                },
                                "finish_reason": "stop",
                            }
                        ],
                        "usage": {
                            "prompt_tokens": 24,
                            "completion_tokens": 15,
                            "total_tokens": 39,
                        },
                    },
                },
                "error": None,
            }
        }
    )
